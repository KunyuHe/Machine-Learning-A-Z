{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Author: Kunyu He*\n",
    "#### *University of Chicago, CAPP'20*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2,\n",
    "                                   zoom_range=0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"dataset/training_set\",\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode=\"binary\")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\"dataset/test_set\",\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 434s 543ms/step - loss: 0.6144 - acc: 0.6525 - val_loss: 0.5471 - val_acc: 0.7295\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.4868 - acc: 0.7649 - val_loss: 0.4476 - val_acc: 0.7851\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 120s 150ms/step - loss: 0.4162 - acc: 0.8061 - val_loss: 0.4311 - val_acc: 0.7922\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 115s 143ms/step - loss: 0.3650 - acc: 0.8323 - val_loss: 0.4107 - val_acc: 0.8259\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 115s 144ms/step - loss: 0.3168 - acc: 0.8595 - val_loss: 0.3704 - val_acc: 0.8317\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 260s 325ms/step - loss: 0.2733 - acc: 0.8831 - val_loss: 0.3897 - val_acc: 0.8353\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.2392 - acc: 0.8993 - val_loss: 0.4346 - val_acc: 0.8188\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.2072 - acc: 0.9132 - val_loss: 0.4491 - val_acc: 0.8372\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.1700 - acc: 0.9321 - val_loss: 0.5307 - val_acc: 0.8273\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.1502 - acc: 0.9397 - val_loss: 0.4738 - val_acc: 0.8372\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.1317 - acc: 0.9493 - val_loss: 0.5502 - val_acc: 0.8349\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.1159 - acc: 0.9547 - val_loss: 0.5379 - val_acc: 0.8386\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0988 - acc: 0.9626 - val_loss: 0.6238 - val_acc: 0.8311\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 113s 142ms/step - loss: 0.0924 - acc: 0.9655 - val_loss: 0.6613 - val_acc: 0.8339\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.0849 - acc: 0.9682 - val_loss: 0.6641 - val_acc: 0.8251\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 113s 141ms/step - loss: 0.0768 - acc: 0.9720 - val_loss: 0.5882 - val_acc: 0.8451\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0698 - acc: 0.9745 - val_loss: 0.7050 - val_acc: 0.8334\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0653 - acc: 0.9759 - val_loss: 0.7982 - val_acc: 0.8396\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0647 - acc: 0.9757 - val_loss: 0.7221 - val_acc: 0.8391\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0594 - acc: 0.9789 - val_loss: 0.8514 - val_acc: 0.8205\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.0518 - acc: 0.9807 - val_loss: 0.7661 - val_acc: 0.8355\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 115s 143ms/step - loss: 0.0533 - acc: 0.9811 - val_loss: 0.7518 - val_acc: 0.8374\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 114s 143ms/step - loss: 0.0545 - acc: 0.9804 - val_loss: 0.7209 - val_acc: 0.8257\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0475 - acc: 0.9832 - val_loss: 0.8116 - val_acc: 0.8367\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 114s 142ms/step - loss: 0.0466 - acc: 0.9829 - val_loss: 0.9116 - val_acc: 0.8397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13426a30d68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(training_set,\n",
    "                  steps_per_epoch=800, epochs=25,\n",
    "                  validation_data=test_set,\n",
    "                  validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some over-fitting. Try a less complex one with higher resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation=\"relu\"))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "cnn.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"dataset/training_set\",\n",
    "                                                 target_size=(128, 128),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode=\"binary\")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\"dataset/test_set\",\n",
    "                                            target_size=(128, 128),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 108s 430ms/step - loss: 0.6630 - acc: 0.5856 - val_loss: 0.6063 - val_acc: 0.6875\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.5744 - acc: 0.7049 - val_loss: 0.5563 - val_acc: 0.7205\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.5350 - acc: 0.7305 - val_loss: 0.5394 - val_acc: 0.7436\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.4921 - acc: 0.7640 - val_loss: 0.4983 - val_acc: 0.7594\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.4620 - acc: 0.7816 - val_loss: 0.4554 - val_acc: 0.7854\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.4353 - acc: 0.7978 - val_loss: 0.4437 - val_acc: 0.7943\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.4204 - acc: 0.8069 - val_loss: 0.4311 - val_acc: 0.8061\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.3917 - acc: 0.8217 - val_loss: 0.4430 - val_acc: 0.8027\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.3938 - acc: 0.8197 - val_loss: 0.3963 - val_acc: 0.8287\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.3640 - acc: 0.8364 - val_loss: 0.3970 - val_acc: 0.8376\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 170s 682ms/step - loss: 0.3484 - acc: 0.8445 - val_loss: 0.4097 - val_acc: 0.8204\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 82s 330ms/step - loss: 0.3261 - acc: 0.8605 - val_loss: 0.4104 - val_acc: 0.8253\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.3300 - acc: 0.8518 - val_loss: 0.4117 - val_acc: 0.8287\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 164s 656ms/step - loss: 0.3158 - acc: 0.8628 - val_loss: 0.4095 - val_acc: 0.8391\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 70s 279ms/step - loss: 0.2943 - acc: 0.8754 - val_loss: 0.3773 - val_acc: 0.8425\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 60s 242ms/step - loss: 0.2888 - acc: 0.8742 - val_loss: 0.3877 - val_acc: 0.8391\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.2695 - acc: 0.8845 - val_loss: 0.4182 - val_acc: 0.8420\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.2528 - acc: 0.8961 - val_loss: 0.3999 - val_acc: 0.8489\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.2395 - acc: 0.8979 - val_loss: 0.4071 - val_acc: 0.8351\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.2328 - acc: 0.9084 - val_loss: 0.3909 - val_acc: 0.8499\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.2170 - acc: 0.9124 - val_loss: 0.4224 - val_acc: 0.8514\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.1991 - acc: 0.9187 - val_loss: 0.3942 - val_acc: 0.8538\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.1940 - acc: 0.9215 - val_loss: 0.4286 - val_acc: 0.8391\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.1799 - acc: 0.9311 - val_loss: 0.4628 - val_acc: 0.8376\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.1690 - acc: 0.9337 - val_loss: 0.4562 - val_acc: 0.8519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1343b01b390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(training_set,\n",
    "                  steps_per_epoch=250, epochs=25,\n",
    "                  validation_data=test_set,\n",
    "                  validation_steps=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy rate on the test set is rather satisfying, and our CNN seems less likely to over-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
